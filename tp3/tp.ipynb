{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> Bastien LE CHENADEC\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(num_embeddings=ntoken, embedding_dim=nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid=nhid, dropout=dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=nhid, nhead=nhead, dim_feedforward=nhid, dropout=dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout=dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base.forward(src, src_mask)\n",
        "        # classifier model\n",
        "        output = torch.softmax(self.classifier.forward(x), dim=-1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhb2gkUhJMR0",
        "outputId": "85e02db6-3f07-4446-c129-52dbd0b245a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjd26ghWuff",
        "outputId": "5b1dee1b-af52-4869-8303-3931020e0436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-31 15:07:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.2’\n",
            "\n",
            "dict.txt.2          100%[===================>] 564.05K  2.83MB/s    in 0.2s    \n",
            "\n",
            "2023-10-31 15:07:14 (2.83 MB/s) - ‘dict.txt.2’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdH_-JeFbGA",
        "outputId": "b685beec-39a9-4dd5-e36c-615b281c2584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  4 + idx\n",
        "\n",
        "ind2token = {idx: word for idx, word in enumerate(token2ind)}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [token2ind[\"<sos>\"]] + [self.token2ind[token] if token in self.token2ind else token2ind[\"<oov>\"] for token in sequence ]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1, :, :]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(token2ind.values())\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwh3n9xZQy4e",
        "outputId": "72e58a8b-9d3b-4e9a-ee96-fc0d7ab6ada8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-31 15:07:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.2’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  28.1MB/s    in 0.3s    \n",
            "\n",
            "2023-10-31 15:07:15 (28.1 MB/s) - ‘pretraining_subset.txt.2’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m11g4ScjZaR",
        "outputId": "48271f5f-ce5f-4915-8473-2336230fed60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 10.80769 | ppl 49399.146\n",
            "| epoch   1 |  1000/ 3125 steps | loss 10.78309 | ppl 48198.836\n",
            "| epoch   1 |  1500/ 3125 steps | loss 10.78033 | ppl 48065.901\n",
            "| epoch   1 |  2000/ 3125 steps | loss 10.75705 | ppl 46959.796\n",
            "| epoch   1 |  2500/ 3125 steps | loss 10.75375 | ppl 46805.155\n",
            "| epoch   1 |  3000/ 3125 steps | loss 10.75298 | ppl 46769.000\n",
            "| epoch   2 |   500/ 3125 steps | loss 10.77580 | ppl 47848.657\n",
            "| epoch   2 |  1000/ 3125 steps | loss 10.75299 | ppl 46769.822\n",
            "| epoch   2 |  1500/ 3125 steps | loss 10.75320 | ppl 46779.571\n",
            "| epoch   2 |  2000/ 3125 steps | loss 10.75250 | ppl 46746.943\n",
            "| epoch   2 |  2500/ 3125 steps | loss 10.75316 | ppl 46777.712\n",
            "| epoch   2 |  3000/ 3125 steps | loss 10.75317 | ppl 46777.931\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BcBC6FSkMH3",
        "outputId": "6d202173-4c3d-4888-a0d5-1a4cfcf653a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-31 15:13:06--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.3’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M  82.5MB/s    in 1.0s    \n",
            "\n",
            "2023-10-31 15:13:08 (82.5 MB/s) - ‘pretrained_model_4layers.pt.3’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBRRVsWqlIoQ",
        "outputId": "6390373e-7ffc-4711-b1a1-7f102ca53216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "--2023-10-31 15:13:12--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.1’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  5.38MB/s    in 0.2s    \n",
            "\n",
            "2023-10-31 15:13:13 (5.38 MB/s) - ‘sentencepiece.french.model.1’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  torch.argmax(out[-1, :]).item()\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    current_length = len(s.encode_as_pieces(sent))\n",
        "    while current_length < max_len:\n",
        "        next_token_ind, out = infer_next_token(sent)\n",
        "        sent += ' ' + ind2token[next_token_ind]\n",
        "        current_length += 1\n",
        "        if next_token_ind == token2ind['<eos>']:\n",
        "            break\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f83Nn5nSly4v",
        "outputId": "fac4195c-72e9-4430-a68a-ad6e3dab4061"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bonjour les ▁gens ▁qui ▁ont ▁été ▁très ▁accueillants ▁et ▁sympathiques . <eos>'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1BZsblmEmx",
        "outputId": "4c28ad78-93c0-4c60-eb08-588732c0d4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-31 15:13:13--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.1’\n",
            "\n",
            "train.review.spm.1  100%[===================>]   1.43M  6.67MB/s    in 0.2s    \n",
            "\n",
            "2023-10-31 15:13:13 (6.67 MB/s) - ‘train.review.spm.1’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-31 15:13:13--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.1’\n",
            "\n",
            "train.label.1       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 15:13:14 (29.6 MB/s) - ‘train.label.1’ saved [3200/3200]\n",
            "\n",
            "--2023-10-31 15:13:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.1’\n",
            "\n",
            "test.review.spm.1   100%[===================>]   1.78M  7.36MB/s    in 0.2s    \n",
            "\n",
            "2023-10-31 15:13:14 (7.36 MB/s) - ‘test.review.spm.1’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-31 15:13:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.1’\n",
            "\n",
            "test.label.1        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 15:13:15 (65.0 MB/s) - ‘test.label.1’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    successes = 0\n",
        "    failures = 0\n",
        "    for data in data_loader:\n",
        "        x, y = data[0], data[1]\n",
        "        y = y.to(device)\n",
        "        src_mask = model.base.generate_square_subsequent_mask(x.size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        out = model(x.to(device), src_mask)\n",
        "        out = out[-1, :]\n",
        "        prediction = torch.argmax(out, dim=-1)\n",
        "        successes += torch.sum(y == prediction).item()\n",
        "        failures += torch.sum(y != prediction).item()\n",
        "    return successes / (successes + failures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-xclMCpnVpw",
        "outputId": "d4bf77cd-97b1-470a-dafb-e84f5af4e04b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.72604 | ppl    2.067\n",
            "| epoch   1 |   100/  200 steps | loss 0.72103 | ppl    2.057\n",
            "| epoch   1 |   150/  200 steps | loss 0.69474 | ppl    2.003\n",
            "| epoch   2 |    50/  200 steps | loss 0.67465 | ppl    1.963\n",
            "| epoch   2 |   100/  200 steps | loss 0.64416 | ppl    1.904\n",
            "| epoch   2 |   150/  200 steps | loss 0.64461 | ppl    1.905\n",
            "| epoch   3 |    50/  200 steps | loss 0.55532 | ppl    1.742\n",
            "| epoch   3 |   100/  200 steps | loss 0.50847 | ppl    1.663\n",
            "| epoch   3 |   150/  200 steps | loss 0.51498 | ppl    1.674\n",
            "| epoch   4 |    50/  200 steps | loss 0.47234 | ppl    1.604\n",
            "| epoch   4 |   100/  200 steps | loss 0.43170 | ppl    1.540\n",
            "| epoch   4 |   150/  200 steps | loss 0.41196 | ppl    1.510\n",
            "| epoch   5 |    50/  200 steps | loss 0.36244 | ppl    1.437\n",
            "| epoch   5 |   100/  200 steps | loss 0.37688 | ppl    1.458\n",
            "| epoch   5 |   150/  200 steps | loss 0.35773 | ppl    1.430\n",
            "| epoch   6 |    50/  200 steps | loss 0.35407 | ppl    1.425\n",
            "| epoch   6 |   100/  200 steps | loss 0.33949 | ppl    1.404\n",
            "| epoch   6 |   150/  200 steps | loss 0.35850 | ppl    1.431\n",
            "| epoch   7 |    50/  200 steps | loss 0.32726 | ppl    1.387\n",
            "| epoch   7 |   100/  200 steps | loss 0.34081 | ppl    1.406\n",
            "| epoch   7 |   150/  200 steps | loss 0.33025 | ppl    1.391\n",
            "| epoch   8 |    50/  200 steps | loss 0.33806 | ppl    1.402\n",
            "| epoch   8 |   100/  200 steps | loss 0.32611 | ppl    1.386\n",
            "| epoch   8 |   150/  200 steps | loss 0.33085 | ppl    1.392\n",
            "| epoch   9 |    50/  200 steps | loss 0.33010 | ppl    1.391\n",
            "| epoch   9 |   100/  200 steps | loss 0.33067 | ppl    1.392\n",
            "| epoch   9 |   150/  200 steps | loss 0.31819 | ppl    1.375\n",
            "| epoch  10 |    50/  200 steps | loss 0.32681 | ppl    1.387\n",
            "| epoch  10 |   100/  200 steps | loss 0.32586 | ppl    1.385\n",
            "| epoch  10 |   150/  200 steps | loss 0.32327 | ppl    1.382\n",
            "| epoch  11 |    50/  200 steps | loss 0.33953 | ppl    1.404\n",
            "| epoch  11 |   100/  200 steps | loss 0.32472 | ppl    1.384\n",
            "| epoch  11 |   150/  200 steps | loss 0.31926 | ppl    1.376\n",
            "| epoch  12 |    50/  200 steps | loss 0.33464 | ppl    1.397\n",
            "| epoch  12 |   100/  200 steps | loss 0.31827 | ppl    1.375\n",
            "| epoch  12 |   150/  200 steps | loss 0.31577 | ppl    1.371\n",
            "| epoch  13 |    50/  200 steps | loss 0.32453 | ppl    1.383\n",
            "| epoch  13 |   100/  200 steps | loss 0.32076 | ppl    1.378\n",
            "| epoch  13 |   150/  200 steps | loss 0.32077 | ppl    1.378\n",
            "| epoch  14 |    50/  200 steps | loss 0.32703 | ppl    1.387\n",
            "| epoch  14 |   100/  200 steps | loss 0.31826 | ppl    1.375\n",
            "| epoch  14 |   150/  200 steps | loss 0.31576 | ppl    1.371\n",
            "| epoch  15 |    50/  200 steps | loss 0.32703 | ppl    1.387\n",
            "| epoch  15 |   100/  200 steps | loss 0.31827 | ppl    1.375\n",
            "| epoch  15 |   150/  200 steps | loss 0.32076 | ppl    1.378\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.72302 | ppl    2.061\n",
            "| epoch   1 |   100/  200 steps | loss 0.65840 | ppl    1.932\n",
            "| epoch   1 |   150/  200 steps | loss 0.62165 | ppl    1.862\n",
            "| epoch   2 |    50/  200 steps | loss 0.53228 | ppl    1.703\n",
            "| epoch   2 |   100/  200 steps | loss 0.49545 | ppl    1.641\n",
            "| epoch   2 |   150/  200 steps | loss 0.49771 | ppl    1.645\n",
            "| epoch   3 |    50/  200 steps | loss 0.47083 | ppl    1.601\n",
            "| epoch   3 |   100/  200 steps | loss 0.44705 | ppl    1.564\n",
            "| epoch   3 |   150/  200 steps | loss 0.46329 | ppl    1.589\n",
            "| epoch   4 |    50/  200 steps | loss 0.48319 | ppl    1.621\n",
            "| epoch   4 |   100/  200 steps | loss 0.41473 | ppl    1.514\n",
            "| epoch   4 |   150/  200 steps | loss 0.42272 | ppl    1.526\n",
            "| epoch   5 |    50/  200 steps | loss 0.42401 | ppl    1.528\n",
            "| epoch   5 |   100/  200 steps | loss 0.42355 | ppl    1.527\n",
            "| epoch   5 |   150/  200 steps | loss 0.39117 | ppl    1.479\n",
            "| epoch   6 |    50/  200 steps | loss 0.40570 | ppl    1.500\n",
            "| epoch   6 |   100/  200 steps | loss 0.37381 | ppl    1.453\n",
            "| epoch   6 |   150/  200 steps | loss 0.38808 | ppl    1.474\n",
            "| epoch   7 |    50/  200 steps | loss 0.36558 | ppl    1.441\n",
            "| epoch   7 |   100/  200 steps | loss 0.38804 | ppl    1.474\n",
            "| epoch   7 |   150/  200 steps | loss 0.35834 | ppl    1.431\n",
            "| epoch   8 |    50/  200 steps | loss 0.37968 | ppl    1.462\n",
            "| epoch   8 |   100/  200 steps | loss 0.36290 | ppl    1.437\n",
            "| epoch   8 |   150/  200 steps | loss 0.35384 | ppl    1.425\n",
            "| epoch   9 |    50/  200 steps | loss 0.36857 | ppl    1.446\n",
            "| epoch   9 |   100/  200 steps | loss 0.35810 | ppl    1.431\n",
            "| epoch   9 |   150/  200 steps | loss 0.36415 | ppl    1.439\n",
            "| epoch  10 |    50/  200 steps | loss 0.37249 | ppl    1.451\n",
            "| epoch  10 |   100/  200 steps | loss 0.35578 | ppl    1.427\n",
            "| epoch  10 |   150/  200 steps | loss 0.36083 | ppl    1.435\n",
            "| epoch  11 |    50/  200 steps | loss 0.36745 | ppl    1.444\n",
            "| epoch  11 |   100/  200 steps | loss 0.35079 | ppl    1.420\n",
            "| epoch  11 |   150/  200 steps | loss 0.35310 | ppl    1.423\n",
            "| epoch  12 |    50/  200 steps | loss 0.38222 | ppl    1.466\n",
            "| epoch  12 |   100/  200 steps | loss 0.35398 | ppl    1.425\n",
            "| epoch  12 |   150/  200 steps | loss 0.35879 | ppl    1.432\n",
            "| epoch  13 |    50/  200 steps | loss 0.35984 | ppl    1.433\n",
            "| epoch  13 |   100/  200 steps | loss 0.36040 | ppl    1.434\n",
            "| epoch  13 |   150/  200 steps | loss 0.36671 | ppl    1.443\n",
            "| epoch  14 |    50/  200 steps | loss 0.34440 | ppl    1.411\n",
            "| epoch  14 |   100/  200 steps | loss 0.35508 | ppl    1.426\n",
            "| epoch  14 |   150/  200 steps | loss 0.36517 | ppl    1.441\n",
            "| epoch  15 |    50/  200 steps | loss 0.35577 | ppl    1.427\n",
            "| epoch  15 |   100/  200 steps | loss 0.34827 | ppl    1.417\n",
            "| epoch  15 |   150/  200 steps | loss 0.35076 | ppl    1.420\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "RCpBIdTHojm6",
        "outputId": "93dcfb73-e3dc-4ac7-e461-7180c2743eb4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(from_scratch_valid_acc, label='Training from scratch')\n",
        "plt.plot(pretrained_valid_acc, label='Pretrained')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
